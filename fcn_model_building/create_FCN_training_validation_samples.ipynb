{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d076506",
   "metadata": {
    "id": "4d076506"
   },
   "source": [
    "# berryFieldImageSegmentation\n",
    "\n",
    "This notebook provides code to take full-sized annotated images and cut them up to develop a training/test set for evaluating the FCN model for identifying berries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e5a14b",
   "metadata": {
    "id": "52e5a14b"
   },
   "source": [
    "## Set user parameters\n",
    "\n",
    "Set specific parameters for this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "-a6Oocjd2Wu-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1638217561889,
     "user": {
      "displayName": "Jeffrey Neyhart",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjahRjzO3gUVe3UziZ_NQjUdwYTl4KeSKpqxk5a=s64",
      "userId": "07720342469706758133"
     },
     "user_tz": 300
    },
    "id": "-a6Oocjd2Wu-",
    "outputId": "b8bd0897-ccfe-4dbf-8a57-05277fe056e6"
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "#### Set user parameters ####\n",
    "#############################\n",
    "\n",
    "# Create a dictionary of training sets with input image sizes and image grid sizes\n",
    "# \"name\": [output_image_size, (h, w) of output image grid, image_ext]\n",
    "training_sets_dict = {\n",
    "#     \"train_use\": [500, (3, 3), \"jpg\"],\n",
    "    \"train0500\": [500, (3, 3), \"jpg\"],\n",
    "    \"train0750\": [750, (2, 2), \"jpg\"],\n",
    "    \"train1500\": [1500, (1, 1), \"jpg\"],\n",
    "    \"train0500_png\": [500, (3, 3), \"png\"],\n",
    "    \"train0750_png\": [750, (2, 2), \"png\"],\n",
    "    \"train1500_png\": [1500, (1, 1), \"png\"]\n",
    "}\n",
    "\n",
    "\n",
    "# Proportion of images to use as testing\n",
    "pTest = 0.2\n",
    "\n",
    "# The image extension name\n",
    "input_image_ext = \"jpg\"\n",
    "\n",
    "# Project directory\n",
    "proj_dir = \"C:/Users/jeffrey.neyhart/OneDrive - USDA/Documents/CranberryLab/Phenomics/phenoCartImageAnalysis/berryImageSegmentation/FCN_Semantic_Segmentation_Model_Training\"\n",
    "\n",
    "# Directory containing the images\n",
    "full_image_dir = \"C:/Users/jeffrey.neyhart/OneDrive - USDA/Documents/CranberryLab/Phenomics/phenoCartImageAnalysis/berryImageSegmentation/trainingSetConstruction_imageSegmentation/images\"\n",
    "# Directory containing the masks\n",
    "full_mask_dir = \"C:/Users/jeffrey.neyhart/OneDrive - USDA/Documents/CranberryLab/Phenomics/phenoCartImageAnalysis/berryImageSegmentation/trainingSetConstruction_imageSegmentation/berryMasks\"\n",
    "\n",
    "\n",
    "# Flag to indicate whether independent testing should be performed\n",
    "# If True, the testing images will not be included in the training images\n",
    "# If False, the testing images will overlap with the training images\n",
    "perform_independent_testing = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vAtGLCPwkFlN",
   "metadata": {
    "id": "vAtGLCPwkFlN"
   },
   "source": [
    "## Additional setup\n",
    "\n",
    "Load packages and set other directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1205ee02",
   "metadata": {
    "id": "1205ee02",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "#### Load packages and set other paths ####\n",
    "###########################################\n",
    "\n",
    "# Load packages\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "\n",
    "# From https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "\n",
    "# Train and test dirs\n",
    "for dir1 in training_sets_dict:\n",
    "    for dir2 in [\"train\", \"test\"]:\n",
    "        for dir3 in [\"images\", \"masks\"]:\n",
    "            full_dir = os.path.join(dir1, dir2, dir3)\n",
    "            if os.path.exists(full_dir):\n",
    "                shutil.rmtree(full_dir)\n",
    "            os.makedirs(full_dir)\n",
    "            \n",
    "\n",
    "## Sample and copy images ##\n",
    "\n",
    "# List all of the images\n",
    "all_images = [os.path.join(full_image_dir, x) for x in os.listdir(full_image_dir) if input_image_ext.upper() in x.upper()]\n",
    "# List all of the masks\n",
    "all_masks = [os.path.join(full_mask_dir, x) for x in os.listdir(full_mask_dir) if input_image_ext.upper() in x.upper()]\n",
    "\n",
    "## Make sure all of the images are of the same dimension\n",
    "# Read in all images and store the dimensions; find the largest and smallest lengths/widths\n",
    "image_dims = []\n",
    "for img_file in all_images:\n",
    "    img = Image.open(img_file)\n",
    "    image_dims.append([os.path.basename(img_file)] + list(img.size))\n",
    "\n",
    "# Calculate the minimum width and height\n",
    "min_h = np.min([x[2] for x in image_dims])\n",
    "min_w = np.min([x[1] for x in image_dims])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25427565",
   "metadata": {},
   "source": [
    "## Allocate images to training or testing\n",
    "\n",
    "List the images that will go to training or testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4cdd23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "#### Allocate images to train/test ####\n",
    "#######################################\n",
    "\n",
    "# List the basenames of the images\n",
    "image_basenames = [os.path.basename(x) for x in all_images]\n",
    "mask_basenames = [os.path.basename(x) for x in all_masks]\n",
    "\n",
    "# Find only images with masks\n",
    "mask_basenames1 = [x for x in mask_basenames if x.replace(\"_berry.\" + input_image_ext, \"\") in [y.replace(\".\" + input_image_ext, \"\") for y in image_basenames]]\n",
    "image_basenames1 = [x for x in image_basenames if x.replace(\".\" + input_image_ext, \"\") in [y.replace(\"_berry.\" + input_image_ext, \"\") for y in mask_basenames]]\n",
    "\n",
    "# List all basenames\n",
    "all_basenames = [x.replace(\".\" + input_image_ext, \"\") for x in image_basenames1]\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random.seed(943)\n",
    "# Sample basenames\n",
    "test_basenames = random.sample(all_basenames, int(np.floor(pTest * len(all_basenames))))\n",
    "train_basenames = [x for x in all_basenames if x not in test_basenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T5qDnwiGZAdm",
   "metadata": {
    "id": "T5qDnwiGZAdm"
   },
   "source": [
    "## Image resizing and splitting\n",
    "\n",
    "Cut each image on center to the desired grid size `unsplit_image_size`\n",
    "\n",
    "Then, split each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21991a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#### Image resizing and splitting ####\n",
    "######################################\n",
    "\n",
    "# Iterate over the training set parameters\n",
    "for train_key in training_sets_dict:\n",
    "    \n",
    "    train_val = training_sets_dict[train_key]\n",
    "    \n",
    "    # Get the image grid size and input image size\n",
    "    input_image_size = train_val[0]\n",
    "    r, c = train_val[1]\n",
    "    unsplit_image_size = [r * input_image_size, c * input_image_size]\n",
    "    out_image_ext = train_val[2]\n",
    "    \n",
    "    # Set the train and test dirs\n",
    "    train_dir = os.path.join(train_key, \"train\")\n",
    "    test_dir = os.path.join(train_key, \"test\")\n",
    "    \n",
    "    # Set an image counter\n",
    "    idx = 1\n",
    "\n",
    "    # Iterate over all of the basenames\n",
    "    for img_basename in all_basenames:\n",
    "    # img_basename = all_basenames[0]\n",
    "\n",
    "        # Find the image path\n",
    "        image_path = [x for x in all_images if img_basename in x][0]\n",
    "        # Read in the image\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        ##### Crop the image #####\n",
    "\n",
    "        # Crop to middle\n",
    "        w, h = img.size\n",
    "        to_crop_height = h - unsplit_image_size[0]\n",
    "        to_crop_width = w - unsplit_image_size[1]\n",
    "        to_crop_top = int(to_crop_height / 2)\n",
    "        to_crop_bottom = to_crop_height - to_crop_top\n",
    "        to_crop_right = int(to_crop_width / 2)\n",
    "        to_crop_left = to_crop_width - to_crop_right\n",
    "\n",
    "        # Pixels to keep\n",
    "        hstart = to_crop_top\n",
    "        hend = h - to_crop_bottom\n",
    "        wstart = to_crop_left\n",
    "        wend = w - to_crop_right\n",
    "\n",
    "        # Crop\n",
    "        img2 = img.crop((wstart, hstart, wend, hend))\n",
    "\n",
    "        # Find the mask; read in\n",
    "        mask_file = [x for x in all_masks if img_basename in x][0]\n",
    "        msk = Image.open(mask_file)\n",
    "        # Crop the mask\n",
    "        msk2 = msk.crop((wstart, hstart, wend, hend))\n",
    "\n",
    "        ##### Split the image #####\n",
    "\n",
    "        # Is it a train image or test image?\n",
    "        is_train = img_basename in train_basenames\n",
    "\n",
    "        # List column (width) and rows (height)\n",
    "        cols, rows = img2.size\n",
    "\n",
    "        # Iterate over rows\n",
    "        for r in range(0, rows, input_image_size):\n",
    "            # Iterate over columns\n",
    "            for c in range(0, cols, input_image_size):\n",
    "                # Determine left, top, right, bottom\n",
    "                left, top, right, bottom = c, r, c + input_image_size, r + input_image_size\n",
    "                # Crop, convert to array\n",
    "                img2_split_i = img2.crop((left, top, right, bottom))\n",
    "                msk2_split_i = msk2.crop((left, top, right, bottom))\n",
    "\n",
    "                img2_split_i_arr = cv.cvtColor(np.asarray(img2_split_i), cv.COLOR_BGR2RGB)\n",
    "                msk2_split_i_arr = np.asarray(msk2_split_i)\n",
    "\n",
    "                # If all elements of msk2_split_i_arr == 255, invert it\n",
    "                if (msk2_split_i_arr == 255).all():\n",
    "                    msk2_split_i_arr = msk2_split_i_arr - 255\n",
    "\n",
    "                # Save the image and the mask\n",
    "                # Include the image number\n",
    "                img_save_base = img_basename.replace(\"cropped\", f\"{r}_{c}_image\" + str(idx).zfill(4) + \".\" + out_image_ext)\n",
    "                if is_train:\n",
    "                    img_filename = os.path.join(train_dir, \"images\", img_save_base)\n",
    "                    msk_filename = os.path.join(train_dir, \"masks\", img_save_base)\n",
    "                else:\n",
    "                    img_filename = os.path.join(test_dir, \"images\", img_save_base)\n",
    "                    msk_filename = os.path.join(test_dir, \"masks\", img_save_base)\n",
    "\n",
    "                # Save the image\n",
    "                cv.imwrite(img_filename, img2_split_i_arr)\n",
    "                # Save the mask\n",
    "                cv.imwrite(msk_filename, msk2_split_i_arr)\n",
    "\n",
    "                # Increase the image counter\n",
    "                idx+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e614ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "create_FCN_training_validation_samples.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
