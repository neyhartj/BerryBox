{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d076506",
   "metadata": {},
   "source": [
    "# BerryBox\n",
    "\n",
    "This notebook will prepare images as training sets for a FCN workflow to identify berries in images. Specifically, it will:  \n",
    "+ Rotate images (if necessary)\n",
    "+ Perform color correction\n",
    "+ Create masks for training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aba9833",
   "metadata": {},
   "source": [
    "## User input\n",
    "\n",
    "Edit the following:\n",
    "\n",
    "**image_directory**: full path to the folder that contains the berry box images.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "50b9bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the following inputs\n",
    "project_directory = \"C:/Users/jeffrey.neyhart/OneDrive - USDA/Documents/CranberryLab/Phenomics/BerryBox/\"\n",
    "input_image_directory = project_directory + \"/testPhotos\"\n",
    "output_image_directory = project_directory + \"/fcn_model_building/imagesToAnnotate\"\n",
    "color_correction_standard = project_directory + \"/resources/color_checker_standard1.JPG\"\n",
    "bayes_classifier_pdf = \"C:/Users/jeffrey.neyhart/OneDrive - USDA/Documents/CranberryLab/Phenomics/BerryBox/resources/bayes_classifier/bayes_classified_pdf.out\"\n",
    "\n",
    "# Image extension\n",
    "ext = \".JPG\"\n",
    "\n",
    "# Run color correction?\n",
    "run_color_correction = False\n",
    "\n",
    "# Rerun all images?\n",
    "rerun_all_images = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e5a14b",
   "metadata": {},
   "source": [
    "## Pipeline setup\n",
    "\n",
    "Load packages, set directories, etc.\n",
    "\n",
    "**Do not alter this or any code below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1205ee02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import cv2 as cv\n",
    "import imageio\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "from plantcv import plantcv as pcv\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border, watershed\n",
    "from skimage.measure import label, regionprops_table, regionprops\n",
    "from skimage.morphology import closing, square\n",
    "from skimage.util import map_array\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.color import label2rgb\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "\n",
    "# Capitalize the extension\n",
    "ext = ext.upper()\n",
    "\n",
    "# List all input images\n",
    "all_images = os.listdir(input_image_directory)\n",
    "# Add the directory name to the image file name\n",
    "all_images = [os.path.join(input_image_directory, x) for x in all_images if ext.upper() in x.upper()]\n",
    "\n",
    "# Create output directory if missing\n",
    "if not os.path.exists(output_image_directory):\n",
    "    os.mkdir(output_image_directory)\n",
    "\n",
    "    \n",
    "#####\n",
    "# Find the color card in the source file\n",
    "#####\n",
    "\n",
    "# Read in the color checker standard file\n",
    "cc_img = imageio.imread(color_correction_standard)\n",
    "h, w, d = cc_img.shape\n",
    "\n",
    "# Find the color card in the color checker standard file\n",
    "# The target image is the image with the color chart and no berries\n",
    "# Downsize\n",
    "scale_percent = 15 # percent of original size\n",
    "new_h = int(h * scale_percent / 100)\n",
    "new_w = int(w * scale_percent / 100)\n",
    "\n",
    "df1, start, space = pcv.transform.find_color_card(rgb_img = cv.resize(cc_img, (new_w, new_h)))\n",
    "\n",
    "# Resize the start and space outputs\n",
    "start_use = [int(x / (scale_percent / 100)) for x in start]\n",
    "start_use = (start_use[0], start_use[1])\n",
    "\n",
    "space_use = [int(x / (scale_percent / 100)) for x in space]\n",
    "space_use = (space_use[0], space_use[1])\n",
    "\n",
    "# Create a mask\n",
    "# Use these outputs to create a labeled color card mask\n",
    "target_mask = pcv.transform.create_color_card_mask(rgb_img = cc_img, radius = 50, start_coord = start_use, \n",
    "                                                   spacing = space_use, ncols = 4, nrows = 6)\n",
    "\n",
    "# get color matrix of target and save\n",
    "target_headers, target_matrix = pcv.transform.get_color_matrix(cc_img, target_mask)\n",
    "\n",
    "\n",
    "# Create an object of class QRCodeDetector\n",
    "qrCodeDetector = cv.QRCodeDetector()\n",
    "\n",
    "# # Open up a text file to store photo name and collection id\n",
    "# image_collection_filename = os.path.join(output_directory, session_name + \"_image_collectionID_link.txt\")\n",
    "# handle = open(image_collection_filename, \"w\")\n",
    "# # Add a header\n",
    "# handle.write(\"\\t\".join([\"image_filename\", \"collection_id\"]) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bab9c2b",
   "metadata": {},
   "source": [
    "## Run the pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e203b98f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from int32 to uint8. Range [0, 1401]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 817]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 874]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 1630]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 3578]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 2555]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 1302]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 3784]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 5796]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 2172]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 4029]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 3046]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 2437]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 1667]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 4390]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 3538]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 3980]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 2580]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 1096]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 1449]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 3545]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 3228]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 1890]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 5064]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 1651]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 2240]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 1803]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 1001]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 880]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 1011]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 863]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 964]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 946]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 1083]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# This code block runs the entire pipeline for images\n",
    "###\n",
    "\n",
    "for img_file in all_images:\n",
    "\n",
    "# # Example image\n",
    "# img_file = all_images[25]\n",
    "\n",
    "    \n",
    "    # Skip this file?\n",
    "    # Set the correct image filename\n",
    "    corrected_image_filename = output_image_directory + \"/\" + os.path.basename(img_file).replace(ext, \"\") + \"-corrected.PNG\"\n",
    "    # Does it exist\n",
    "    if os.path.exists(corrected_image_filename) & (not rerun_all_images):\n",
    "        continue\n",
    "\n",
    "    # Read in the image\n",
    "    img = imageio.imread(img_file)\n",
    "\n",
    "\n",
    "    ###\n",
    "    # Step 1: QR code reader\n",
    "    ###\n",
    "\n",
    "    # Crop the image to speed detection\n",
    "\n",
    "#     # Get the dimensions\n",
    "#     h, w, d = img.shape\n",
    "#     scale_percent = 50\n",
    "#     new_h = int(h * scale_percent / 100)\n",
    "#     new_w = int(w * scale_percent / 100)\n",
    "\n",
    "#     img2_crop = cv.resize(img, (new_w, new_h))\n",
    "\n",
    "#     # # Print the image\n",
    "#     # plt.figure()\n",
    "#     # plt.imshow(img2_crop)\n",
    "#     # plt.show()\n",
    "\n",
    "#     # Detect and decode the QR code\n",
    "#     collection_id, points, _ = qrCodeDetector.detectAndDecode(img2_crop)\n",
    "\n",
    "#     # points is a 4 x 2 matrix where:\n",
    "#     # [bl_x, bl_y]\n",
    "#     # [tl_x, tl_y]\n",
    "#     # [tr_x, tr_y]\n",
    "#     # [br_x, br_y]\n",
    "#     # \n",
    "\n",
    "#     ## Determine if the image should be rotated\n",
    "#     ## \n",
    "#     ## First determine if the image is portrait or landscape\n",
    "#     if h > w:\n",
    "#         # Next determine if the QR code is in the upper half (rotate clockwise) or lower half (rotate\n",
    "#         # counter-clockwise)\n",
    "#         y_min = min([x[1] for x in points[0]])\n",
    "\n",
    "#         img1 = np.asarray(img)\n",
    "\n",
    "#         # If this is true, the qr code is in the upper half\n",
    "#         if y_min < ((h * (scale_percent / 100)) / 2):\n",
    "#             img1 = cv.rotate(img1, cv.ROTATE_90_CLOCKWISE)\n",
    "#         else:\n",
    "#             img1 = cv.rotate(img1, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "#     # Else just copy the image\n",
    "#     else:\n",
    "    img1 = img\n",
    "\n",
    "\n",
    "    ###\n",
    "    # Step 2: Color calibration\n",
    "    ###\n",
    "\n",
    "    # Only run this if run_color_correction = True\n",
    "    if run_color_correction:\n",
    "    \n",
    "        # Use the plant CV Color Correction Workflow\n",
    "        # located here: https://plantcv.readthedocs.io/en/stable/transform_correct_color/\n",
    "\n",
    "        # Find the color checker in the source image\n",
    "        # Downsize\n",
    "        h, w, d = img1.shape\n",
    "        scale_percent = 25 # Keep this at 25 to ensure the color card is identified\n",
    "        new_h = int(h * scale_percent / 100)\n",
    "        new_w = int(w * scale_percent / 100)\n",
    "\n",
    "        df1, start, space = pcv.transform.find_color_card(rgb_img = cv.resize(img1, (new_w, new_h)))\n",
    "\n",
    "        # Resize the start and space outputs\n",
    "        start_use = [int(x / (scale_percent / 100)) for x in start]\n",
    "        start_use = (start_use[0], start_use[1])\n",
    "\n",
    "        space_use = [int(x / (scale_percent / 100)) for x in space]\n",
    "        space_use = (space_use[0], space_use[1])\n",
    "\n",
    "        # Create a mask\n",
    "        # Use these outputs to create a labeled color card mask\n",
    "        source_mask = pcv.transform.create_color_card_mask(rgb_img = img1, radius = 50, start_coord = start_use, \n",
    "                                                           spacing = space_use, ncols = 4, nrows = 6)\n",
    "\n",
    "        # Get the source matrix\n",
    "        source_headers, source_matrix = pcv.transform.get_color_matrix(img1, source_mask)\n",
    "\n",
    "        ## Run color correction ##\n",
    "\n",
    "        # matrix_a is a matrix of average rgb values for each color ship in source_img, matrix_m is a moore-penrose inverse matrix,\n",
    "        # matrix_b is a matrix of average rgb values for each color ship in source_img\n",
    "        matrix_a, matrix_m, matrix_b = pcv.transform.get_matrix_m(target_matrix = target_matrix, source_matrix = source_matrix)\n",
    "\n",
    "        # deviance is the measure of how greatly the source image deviates from the target image's color space. \n",
    "        # Two images of the same color space should have a deviance of ~0.\n",
    "        # transformation_matrix is a 9x9 matrix of transformation coefficients \n",
    "        deviance, transformation_matrix = pcv.transform.calc_transformation_matrix(matrix_m, matrix_b)\n",
    "\n",
    "        img2 = pcv.transform.apply_transformation_matrix(source_img = img1, target_img = cc_img, \n",
    "                                                                  transformation_matrix = transformation_matrix)\n",
    "        \n",
    "    else:\n",
    "        img2 = img1\n",
    "\n",
    "    # Save the corrected image\n",
    "    # New name of the file\n",
    "    imageio.imwrite(corrected_image_filename, img2)\n",
    "\n",
    "\n",
    "\n",
    "    ###\n",
    "    # Step 3: Berry segmentation\n",
    "    ###\n",
    "\n",
    "\n",
    "    # Run the naive bayes classifier\n",
    "    # Information can be found here: https://plantcv.readthedocs.io/en/stable/tutorials/machine_learning_tutorial/\n",
    "    # \n",
    "\n",
    "    # Try resizing to speed up\n",
    "    h, w, d = img2.shape\n",
    "    scale_percent = 50\n",
    "    new_h = int(h * scale_percent / 100)\n",
    "    new_w = int(w * scale_percent / 100)\n",
    "\n",
    "    img3 = cv.resize(img2, (new_w, new_h))\n",
    "\n",
    "    # Run the classifier\n",
    "    bayes_class_mask = pcv.naive_bayes_classifier(rgb_img = img3, pdf_file = bayes_classifier_pdf)\n",
    "    # Get the berry mask\n",
    "    berry_mask = bayes_class_mask[\"berry\"]\n",
    "\n",
    "    # Run the watershed segmentation\n",
    "    distance = ndi.distance_transform_edt(berry_mask)\n",
    "\n",
    "    local_max_coords = peak_local_max(distance, footprint=np.ones((50, 50)))\n",
    "    local_max_mask = np.zeros(distance.shape, dtype=bool)\n",
    "    local_max_mask[tuple(local_max_coords.T)] = True\n",
    "    markers = label(local_max_mask)\n",
    "\n",
    "    berry_seg = watershed(-distance, markers, mask = berry_mask)\n",
    "    berry_seg = np.array(berry_seg)\n",
    "\n",
    "    # Save\n",
    "    berry_mask_seg_filename = output_image_directory + \"/\" + os.path.basename(img_file).replace(ext, \"\") + \"-berry_mask_watershed.PNG\"\n",
    "    imageio.imwrite(berry_mask_seg_filename, berry_seg)\n",
    "\n",
    "\n",
    "    ## Find and filter regions ##\n",
    "    # Label mat\n",
    "    label_mat = label(berry_seg, background = 0)\n",
    "    if np.sum(label_mat) < 1:\n",
    "        label_mat = np.ones_like(label_mat)\n",
    "    elif np.sum(label_mat) >= 1:\n",
    "        label_mat = label_mat\n",
    "\n",
    "    # Get regions\n",
    "    berry_regions = regionprops_table(label_mat, properties = [\"label\", \"area\", \"eccentricity\"])\n",
    "\n",
    "    # Filter for berry regions\n",
    "    condition = (berry_regions['area'] > 1000) & (berry_regions['area'] < 100000)\n",
    "    # zero out labels not meeting condition\n",
    "    input_labels = berry_regions['label']\n",
    "    output_labels = input_labels * condition\n",
    "    # Create a new mask from the subset of labels\n",
    "    filtered_lab_image = map_array(label_mat, input_labels, output_labels).astype('uint8')\n",
    "\n",
    "    # Threshold\n",
    "    berry_mask1 = closing(filtered_lab_image > 0).astype(\"uint8\")\n",
    "    berry_mask2 = cv.resize(berry_mask1, (w, h))\n",
    "\n",
    "    # Save the mask\n",
    "    berry_mask_filename = output_image_directory + \"/\" + os.path.basename(img_file).replace(ext, \"\") + \"-berry_mask.PNG\"\n",
    "    imageio.imwrite(berry_mask_filename, berry_mask2 * 255) # Need to rescale to 0-255 to save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55d8dcb",
   "metadata": {},
   "source": [
    "# COMPONENT CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d036f949",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Example image\n",
    "img_file = all_images[0]\n",
    "\n",
    "# Read in the image\n",
    "img = imageio.imread(img_file)\n",
    "# img = cv.imread(img_file, cv.IMREAD_COLOR)\n",
    "# img = Image.open(img_file)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dc648c",
   "metadata": {},
   "source": [
    "### Step 1: QR code reader\n",
    "\n",
    "This step finds and decodes the QR code in the images. It also determines if the image needs to be rotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf78ccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Crop the image to speed detection\n",
    "\n",
    "# Get the dimensions\n",
    "h, w, d = img.shape\n",
    "scale_percent = 50\n",
    "new_h = int(h * scale_percent / 100)\n",
    "new_w = int(w * scale_percent / 100)\n",
    "\n",
    "img2_crop = cv.resize(img, (new_w, new_h))\n",
    "\n",
    "# # Print the image\n",
    "# plt.figure()\n",
    "# plt.imshow(img2_crop)\n",
    "# plt.show()\n",
    "\n",
    "# Detect and decode the QR code\n",
    "collection_id, points, _ = qrCodeDetector.detectAndDecode(img2_crop)\n",
    "\n",
    "# points is a 4 x 2 matrix where:\n",
    "# [bl_x, bl_y]\n",
    "# [tl_x, tl_y]\n",
    "# [tr_x, tr_y]\n",
    "# [br_x, br_y]\n",
    "# \n",
    "\n",
    "## Determine if the image should be rotated\n",
    "## \n",
    "## First determine if the image is portrait or landscape\n",
    "if h > w:\n",
    "    # Next determine if the QR code is in the upper half (rotate clockwise) or lower half (rotate\n",
    "    # counter-clockwise)\n",
    "    y_min = min([x[1] for x in points[0]])\n",
    "    \n",
    "    img1 = np.asarray(img)\n",
    "    \n",
    "    # If this is true, the qr code is in the upper half\n",
    "    if y_min < ((h * (scale_percent / 100)) / 2):\n",
    "        img1 = cv.rotate(img1, cv.ROTATE_90_CLOCKWISE)\n",
    "    else:\n",
    "        img1 = cv.rotate(img1, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        \n",
    "# Else just copy the image\n",
    "else:\n",
    "    img1 = img\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b23f1d",
   "metadata": {},
   "source": [
    "### Step 2: Color Calibration\n",
    "\n",
    "This step performs color calibration of the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209fc878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the plant CV Color Correction Workflow\n",
    "# located here: https://plantcv.readthedocs.io/en/stable/transform_correct_color/\n",
    "\n",
    "# Find the color checker in the source image\n",
    "# Downsize\n",
    "h, w, d = img1.shape\n",
    "scale_percent = 20\n",
    "new_h = int(h * scale_percent / 100)\n",
    "new_w = int(w * scale_percent / 100)\n",
    "\n",
    "df1, start, space = pcv.transform.find_color_card(rgb_img = cv.resize(img1, (new_w, new_h)))\n",
    "\n",
    "# Resize the start and space outputs\n",
    "start_use = [int(x / (scale_percent / 100)) for x in start]\n",
    "start_use = (start_use[0], start_use[1])\n",
    "\n",
    "space_use = [int(x / (scale_percent / 100)) for x in space]\n",
    "space_use = (space_use[0], space_use[1])\n",
    "\n",
    "# Create a mask\n",
    "# Use these outputs to create a labeled color card mask\n",
    "source_mask = pcv.transform.create_color_card_mask(rgb_img = img1, radius = 50, start_coord = start_use, \n",
    "                                                   spacing = space_use, ncols = 4, nrows = 6)\n",
    "\n",
    "# Get the source matrix\n",
    "source_headers, source_matrix = pcv.transform.get_color_matrix(img1, source_mask)\n",
    "\n",
    "## Run color correction ##\n",
    "\n",
    "# matrix_a is a matrix of average rgb values for each color ship in source_img, matrix_m is a moore-penrose inverse matrix,\n",
    "# matrix_b is a matrix of average rgb values for each color ship in source_img\n",
    "matrix_a, matrix_m, matrix_b = pcv.transform.get_matrix_m(target_matrix = target_matrix, source_matrix = source_matrix)\n",
    "\n",
    "# deviance is the measure of how greatly the source image deviates from the target image's color space. \n",
    "# Two images of the same color space should have a deviance of ~0.\n",
    "# transformation_matrix is a 9x9 matrix of transformation coefficients \n",
    "deviance, transformation_matrix = pcv.transform.calc_transformation_matrix(matrix_m, matrix_b)\n",
    "\n",
    "img2 = pcv.transform.apply_transformation_matrix(source_img = img1, target_img = cc_img, \n",
    "                                                          transformation_matrix = transformation_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# # Run color correction\n",
    "# target_matrix, source_matrix, transformation_matrix, img2 = pcv.transform.correct_color(target_img=cc_img, \n",
    "#                                                                                         target_mask=target_mask, \n",
    "#                                                                                         source_img=img1, \n",
    "#                                                                                         source_mask=source_mask, \n",
    "#                                                                                         output_directory=\".\")\n",
    "\n",
    "\n",
    "\n",
    "# Save the corrected image\n",
    "# New name of the file\n",
    "corrected_image_filename = output_image_directory + \"/\" + os.path.basename(img_file).replace(ext, \"\") + \"-corrected.PNG\"\n",
    "imageio.imwrite(corrected_image_filename, img2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41a309d",
   "metadata": {},
   "source": [
    "Using the matrix transformation took 13.01 seconds  \n",
    "Using the transform color correction took 10.53 seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a482c",
   "metadata": {},
   "source": [
    "### Step 3: Berry Segmentation\n",
    "\n",
    "This step identifies the berries in the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the naive bayes classifier\n",
    "# Information can be found here: https://plantcv.readthedocs.io/en/stable/tutorials/machine_learning_tutorial/\n",
    "# \n",
    "\n",
    "# Try resizing to speed up\n",
    "h, w, d = img2.shape\n",
    "scale_percent = 100\n",
    "new_h = int(h * scale_percent / 100)\n",
    "new_w = int(w * scale_percent / 100)\n",
    "\n",
    "img3 = cv.resize(img2, (new_w, new_h))\n",
    "\n",
    "# Run the classifier\n",
    "bayes_class_mask = pcv.naive_bayes_classifier(rgb_img = img3, pdf_file = bayes_classifier_pdf)\n",
    "\n",
    "# Get the berry mask\n",
    "berry_mask = bayes_class_mask['berry']\n",
    "\n",
    "plt.imshow(berry_mask, cmap = \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f359eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the watershed segmentation\n",
    "distance = ndi.distance_transform_edt(berry_mask)\n",
    "\n",
    "local_max_coords = feature.peak_local_max(distance, footprint=np.ones((250, 250)))\n",
    "local_max_mask = np.zeros(distance.shape, dtype=bool)\n",
    "local_max_mask[tuple(local_max_coords.T)] = True\n",
    "markers = measure.label(local_max_mask)\n",
    "\n",
    "berry_seg = segmentation.watershed(-distance, markers, mask = berry_mask)\n",
    "berry_seg = np.array(berry_seg)\n",
    "\n",
    "plt.imshow(berry_seg, cmap = \"gray\")\n",
    "plt.show()\n",
    "    \n",
    "# Save\n",
    "berry_mask_seg_filename = output_image_directory + \"/\" + os.path.basename(img_file).replace(ext, \"\") + \"-berry_mask_watershed.PNG\"\n",
    "imageio.imwrite(berry_mask_seg_filename, berry_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c70f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mat\n",
    "label_mat = measure.label(berry_seg, background = 0)\n",
    "if np.sum(label_mat) < 1:\n",
    "    label_mat = np.ones_like(label_mat)\n",
    "elif np.sum(label_mat) >= 1:\n",
    "    label_mat = label_mat\n",
    "\n",
    "# Get regions\n",
    "berry_regions = measure.regionprops_table(label_mat, properties = [\"label\", \"area\", \"eccentricity\"])\n",
    "# Filter for berry regions\n",
    "condition = (berry_regions['area'] > 10000) & (berry_regions['area'] < 90000) & (berry_regions['eccentricity'] > 0.3)\n",
    "\n",
    "# zero out labels not meeting condition\n",
    "input_labels = berry_regions['label']\n",
    "output_labels = input_labels * condition\n",
    "\n",
    "# Create a new mask from the subset of labels\n",
    "filtered_lab_image = util.map_array(label_mat, input_labels, output_labels).astype('uint8')\n",
    "\n",
    "# Threshold\n",
    "ret, berry_mask_bw = cv.threshold(filtered_lab_image * 255, 1, 255, cv.THRESH_BINARY)\n",
    "\n",
    "plt.imshow(berry_mask_bw, cmap = \"gray\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eedf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "berry_mask1 = cv.resize(berry_mask_bw, (w, h))\n",
    "\n",
    "# Save the mask\n",
    "berry_mask_filename = output_image_directory + \"/\" + os.path.basename(img_file).replace(ext, \"\") + \"-berry_mask.PNG\"\n",
    "imageio.imwrite(berry_mask_filename, berry_mask1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d73697f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
